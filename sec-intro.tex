\section{Introduction}

Skeleton-based action recognition has emerged as a critical research 
direction in computer vision, driven by its applications in healthcare 
monitoring \cite{ref1}, human-computer interaction \cite{ref2}, and surveillance systems \cite{ref3}.
Early approaches primarily relied on Recurrent Neural Networks (RNNs) \cite{ref4,ref5} 
to model temporal dependencies and Convolutional Neural Networks (CNNs) \cite{ref6}
to process joint coordinates as pseudo-images. While these methods achieved 
reasonable performance, they struggled to capture the intrinsic spatial 
relationships between joints, particularly for fine-grained actions 
requiring nuanced motion analysis \cite{ref7}.


The advent of Graph Convolutional Networks (GCNs) \cite{ref8} revolutionized the field by 
explicitly modeling skeletal topology through adjacency matrices. Pioneering 
work like ST-GCN \cite{ref7} introduced spatial-temporal convolutions to jointly 
capture joint correlations across frames. Subsequent innovations proposed 
learnable adjacency matrices \cite{ref9,ref10} and multi-scale aggregation 
strategies \cite{ref11} to enhance flexibility.Despite these advancements, 
two critical limitations persist:

Subsequent paragraphs, however, are indented.

一些中文字符。